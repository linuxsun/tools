
kubernetes cluster v1.14.3 

这是原始手工的部署方法，好处是，按这方法做一遍之后对部署流程就很熟悉了。

[root@kube1 ~]# cat /etc/redhat-release 
CentOS Linux release 7.6.1810 (Core) 
[root@kube1 ~]# uname -a                
Linux kube1 3.10.0-957.21.3.el7.x86_64 #1 SMP Tue Jun 18 16:35:19 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

tee /etc/hosts <<-'EOF'
kube1 192.168.20.10 # master
kube2 192.168.20.11 # node1
kube3 192.168.20.12 # node2
EOF

#yum install kubeadm
# yum install kubelet  kubectl

#yum install kubeadm-1.11.1 kubectl-1.11.1 
yum remove kubelet-1.14.3 kubelet-1.14.3 kubectl-1.14.3 kubeadm-1.14.3

##############################

images=(
  kube-apiserver:v1.14.3
  kube-controller-manager:v1.14.3
  kube-scheduler:v1.14.3
  kube-proxy:v1.14.3
  pause:3.1
  etcd:3.3.10
  coredns:1.3.1
)
k8s.gcr.io/kube-apiserver:v1.14.3
k8s.gcr.io/kube-controller-manager:v1.14.3
k8s.gcr.io/kube-scheduler:v1.14.3
k8s.gcr.io/kube-proxy:v1.14.3
k8s.gcr.io/pause:3.1
k8s.gcr.io/etcd:3.3.10
k8s.gcr.io/coredns:1.3.1

for in in ${images[@]} ; do
    docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/$in
    docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/$in k8s.gcr.io/$in
	docker rmi registry.cn-hangzhou.aliyuncs.com/google_containers/$in
done


kubeadm init --pod-network-cidr=192.168.168.0/24 --kubernetes-version=v1.14.3 --apiserver-advertise-address=192.168.20.10
......
[kubelet] Creating a ConfigMap "kubelet-config-1.14" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --experimental-upload-certs
[mark-control-plane] Marking the node kube1 as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node kube1 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: 9ov650.j4nk608oi5rqaaa1
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstraptoken] creating the "cluster-info" ConfigMap in the "kube-public" namespace
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy
Your Kubernetes master has initialized successfully!
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:
kubeadm join 192.168.204.10:6443 --token obq630.1galcwg8y4b2alq6 \
    --discovery-token-ca-cert-hash sha256:2b312b9eb010b034584cc80bcdb1ad99547597047014b2146e454c763e4c5461 


export KUBECONFIG=/etc/kubernetes/admin.conf
echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> /etc/profile

curl -fsSLo weave-daemonset.yaml "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
kubectl apply -f weave-daemonset.yaml


kubectl get nodes
NAME      STATUS     ROLES     AGE       VERSION
master    NotReady   master    1d        v1.14.3

kubectl describe node kube1

# 查看admin-user-token密钥文件
kubectl get secret --all-namespaces
kubectl describe secrets -n kube-system admin-user-token-6fhwn



#删除一个pods
kubectl delete pods kubernetes-dashboard-7d75c474bb-g7xzm

# 查看集群信息
kubectl cluster-info

#查看 Pods 信息
kubectl get pods --all-namespaces

#
kubectl get pod -n kube-system
kubectl describe pod -n kube-system weave-net-chhpd

#重新生成 token kube1
#kubeadm token generate
#kubeadm token create <generated-token> --print-join-command --ttl=24h


# 获取token值.
默认情况下，令牌在24小时后过期
kubeadm token list
TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS
9ov650.j4nk608oi5rqaaa1   23h       2019-07-10T00:02:02+08:00   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token



（可选）将API服务器代理到localhost
如果要从群集外部连接到API服务器，可以使用 kubectl proxy：

scp root@<master ip>:/etc/kubernetes/admin.conf .
kubectl --kubeconfig ./admin.conf proxy
# kubectl proxy --address=192.168.20.12 --disable-filter=true
您现在可以在本地访问API服务器 http://localhost:8001/api/v1



################
安装可视化插件kubernetes-dashboard

该插件可能会随机选中集群中的一台节点去部署dashboard插件容器，所以ssh登录到该节点，先手工把镜像获取下来。
docker pull kubernetesui/dashboard:v2.0.0-beta1
docker pull kubernetesui/metrics-scraper:v1.0.0
wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta1/aio/deploy/recommended.yaml
kubectl create -f recommended.yaml


tee dashboard-adminuser.yaml <<-'EOF'
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kubernetes-dashboard
EOF

tee admin-user-role-binding.yaml <<-'EOF'
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kubernetes-dashboard
EOF

kubectl create -f dashboard-adminuser.yaml 
kubectl create -f admin-user-role-binding.yaml

获取Token
kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')

kubectl get pods --all-namespaces
NAMESPACE              NAME                                          READY     STATUS    RESTARTS   AGE
default                nginx-deployment-5c678cfb6d-6mlnj             1/1       Running   0          2h
default                nginx-deployment-5c678cfb6d-ln9c9             1/1       Running   0          2h
kube-system            coredns-78fcdf6894-46j2d                      1/1       Running   3          3d
......
kube-system            kube-scheduler-kube1                          1/1       Running   4          3d
kube-system            weave-net-86lg2                               2/2       Running   12         3d
kube-system            weave-net-r5dbz                               2/2       Running   8          3d
kubernetes-dashboard   kubernetes-dashboard-7f9898654f-x7495         1/1       Running   0          1h
kubernetes-dashboard   kubernetes-metrics-scraper-7b9df76cdb-pngxq   1/1       Running   0          1h

kubectl cluster-info
Kubernetes master is running at https://192.168.20.10:6443
KubeDNS is running at https://192.168.20.10:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.



kubectl get -f recommended.yaml
NAME                   STATUS    AGE
kubernetes-dashboard   Active    1h
NAME                   SECRETS   AGE
kubernetes-dashboard   1         1h
NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
kubernetes-dashboard   ClusterIP   10.109.221.42   <none>        443/TCP   1h
......
NAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
dashboard-metrics-scraper   ClusterIP   10.100.197.108   <none>        8000/TCP   1h\
NAME                         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
kubernetes-metrics-scraper   1         1         1            1           1h


kubectl --namespace=kubernetes-dashboard logs kubernetes-dashboard-7f9898654f-x7495
......
2019/07/12 16:00:42 [2019-07-12T16:00:42Z] Incoming HTTP/2.0 GET /api/v1/pod/default/nginx-deployment-5c678cfb6d-6mlnj/event?itemsPerPage=10&page=1 request from 10.32.0.1:52730: 
2019/07/12 16:00:42 Getting details of nginx-deployment-5c678cfb6d-6mlnj pod in default namespace
2019/07/12 16:00:42 Getting events related to a pod in namespace
2019/07/12 16:00:42 [2019-07-12T16:00:42Z] Outcoming response to 10.32.0.1:52730 with 200 status code
2019/07/12 16:00:42 No persistentvolumeclaims found related to nginx-deployment-5c678cfb6d-6mlnj pod
2019/07/12 16:00:42 [2019-07-12T16:00:42Z] Outcoming response to 10.32.0.1:52730 with 200 status code


k8s默认启用RBAC
创建一个证书：

使用client-certificate-data和client-key-data生成一个p12文件：
# 生成client-certificate-data
grep 'client-certificate-data' /etc/kubernetes/admin.conf | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.crt

# 生成client-key-data
grep 'client-key-data' /etc/kubernetes/admin.conf | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.key

# 生成kubecfg.p12
openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12 -name "kubernetes-client"

#最后导入上面生成的p12文件，重新打开谷歌浏览器。(建议用谷歌浏览器。)
证书导入向导-->证书存储-->选择：根据证书类型，自动选择证书存储-->下一步-->完成-->导入成功-->关闭-->重启浏览器


访问Kubernetes Dashboard选择 -->Token-->输入Token-->登录
获取Token：kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')
https://192.168.20.10:6443/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login


tee get_token.sh <<-'EOF'
HTTPS=$(kubectl cluster-info|grep -e 'Kubernetes master'|awk '{print $6}')
URI='api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/login'
URL="$HTTPS/$URI"
echo "URL: $URL"
kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')|grep -E "(Namespace|Annotations|token)"
EOF

chmod 750 ./get_token.sh && ./get_token.sh


####################
部署容器存储插件 
Rook 项目是一个基于 Ceph 的 Kubernetes 存储插件 生产级别可用的容器存储插件。 

# 在kube1(Master)执行以下指令：
docker pull rook/ceph:master
docker pull ceph/daemon-base:latest-nautilus-devel

docker save -o rook_ceph.tar rook/ceph:master
docker save -o ceph_daemon-base.tar ceph/daemon-base

分发镜像到kube2地点和kube3节点：
scp rook_ceph.tar kube2:~/rook_ceph.tar
scp ceph_daemon-base.tar kube2:~/ceph_daemon-base.tar
scp rook_ceph.tar kube3:~/rook_ceph.tar
scp ceph_daemon-base.tar kube3:~/ceph_daemon-base.tar

ssh kube2 'docker load < ~/rook_ceph.tar'
ssh kube2 'docker load < ~/ceph_daemon-base.tar'
ssh kube3 'docker load < ~/rook_ceph.tar'
ssh kube3 'docker load < ~/ceph_daemon-base.tar'

# 批量导出镜像
# for i in `docker images|awk '{print $1,$2}'|tr -s ' ' ':' |grep -v 'REPOSITORY:TAG'`; do  img=${i%:*};  ver=${i#*:};  img=${img#*/} ; docker save -o ${img}.tar $i ; done
# scp *.tar root@192.168.90.245:~/

#这里并不是真的用wget下载.yaml文件，而是用浏览器打开三个.yaml文件，手工复制内容下来。
wget https://github.com/rook/rook/blob/master/cluster/examples/kubernetes/ceph/common.yaml
wget https://github.com/rook/rook/blob/master/cluster/examples/kubernetes/ceph/operator.yaml
wget https://github.com/rook/rook/blob/master/cluster/examples/kubernetes/ceph/cluster.yaml

kubectl create -f common.yaml
kubectl create -f operator.yaml
kubectl create -f cluster.yaml

kubectl get pods --all-namespaces    
kubernetes-dashboard   kubernetes-dashboard-6f89577b77-fzbgv         1/1     Running   4          41h
kubernetes-dashboard   kubernetes-metrics-scraper-79c9985bc6-7bj4s   1/1     Running   2          41h
rook-ceph              rook-ceph-agent-hrrzz                         1/1     Running   0          24m
rook-ceph              rook-ceph-agent-tskg2                         1/1     Running   0          24m
rook-ceph              rook-ceph-operator-775cf575c5-g4s97           1/1     Running   0          41m
rook-ceph              rook-discover-7zp9v                           1/1     Running   0          24m
rook-ceph              rook-discover-dz5lc                           1/1     Running   0          24m

kubectl describe pod -n rook-ceph rook-ceph-detect-version-vg9tv
kubectl describe pod -n rook-ceph rook-discover-7zp9v

#kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')


################
参考资料
1. 包v1beta2定义了kubeadm配置文件格式的v1beta2版本。
https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2

2.
https://www.cnblogs.com/RainingNight/p/deploying-k8s-dashboard-ui.html

3. 通过插件集成Kubernetes
https://www.weave.works/docs/net/latest/kubernetes/kube-addon/







	
